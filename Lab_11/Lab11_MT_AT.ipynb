{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPTffTLug7i"
      },
      "source": [
        "# **Laboratorio 11: LLM y Agentes Aut칩nomos 游뱄**\n",
        "\n",
        "MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pbWVyntzbvL"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti치n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol치s Ojeda, Melanie Pe침a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy6ikgVYzghB"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n",
        "\n",
        "- Nombre de alumno 1: Mart칤n Torrico\n",
        "- Nombre de alumno 2: Alejandra Toro\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMJ-owchzjFf"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/MartinTorricoP/Laboratorios_MDS7202)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUuwsXrKzmkK"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Reinforcement Learning\n",
        "- Large Language Models\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Resoluci칩n de problemas secuenciales usando Reinforcement Learning\n",
        "- Habilitar un Chatbot para entregar respuestas 칰tiles usando Large Language Models.\n",
        "\n",
        "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      },
      "source": [
        "## **1. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta secci칩n van a usar m칠todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gOcejYb6uzOO"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBPet_Mq8dX9"
      },
      "source": [
        "### **1.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "La idea de esta subsecci칩n es que puedan implementar m칠todos de RL y as칤 generar una estrategia para jugar el cl치sico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de c칩digo transforma las observaciones del ambiente a `np.array`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      },
      "source": [
        "#### **1.1.1 Descripci칩n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci칩n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci칩n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5i1Wt1p770x"
      },
      "source": [
        "\n",
        "El ambiente de Blackjack adjunto consiste en una partida de Blackjack, juego donde el objetivo es que la suma de tus cartas se mayor a la del dealer sin excederse de los 21 puntos. La formulaci칩n en MDP corresponde a :\n",
        "\n",
        "* Estados:\n",
        "  - Suma actual de las cartas del jugador: Valores entre el 4 al 21.\n",
        "  - Carta visible del dealer: Valores del 1 al 10 (donde 1 es un As).\n",
        "  - As utilizable: Valor 0 o 1 (siendo 1 cuando el jugador puede utilizar un As).\n",
        "\n",
        "* Acciones:\n",
        " - Quedarse con la suma actual: 0 (stick).\n",
        " - Pedir otra carta: 1 (hit).\n",
        "\n",
        "* Recompensas:\n",
        " - Ganar: +1.\n",
        " - Perder: -1.\n",
        " - Empatar: 0.\n",
        " - Ganar con blackjack natural: +1,5 (solo si natural=True).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcX6bRC9agQ"
      },
      "source": [
        "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci칩n 5000 veces y reporte el promedio y desviaci칩n de las recompensas. 쮺칩mo calificar칤a el performance de esta pol칤tica? 쮺칩mo podr칤a interpretar las recompensas obtenidas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p2PrLLR9yju",
        "outputId": "a81d36e8-3614-40df-ef05-1cd41829f012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Promedio de las recompensas: -0.3976\n",
            "Desviaci칩n est치ndar de las recompensas: 0.8948263742201612\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "# Variables para almacenar resultados\n",
        "rewards = []\n",
        "n = 5000 #numero de repeticiones\n",
        "\n",
        "# Simulaci칩n de 5000 episodios con acciones aleatorias\n",
        "for _ in range(n):\n",
        "    obs = env.reset()  # Reiniciar el ambiente\n",
        "    done = False\n",
        "    total = 0\n",
        "\n",
        "    while not done:\n",
        "        action = env.action_space.sample() # Seleccionar una acci칩n aleatoria (0 o 1)\n",
        "        obs, reward, done, _, _ = env.step(action) #Ejecutar la acci칩n\n",
        "        total += reward\n",
        "\n",
        "    rewards.append(total)\n",
        "\n",
        "# Calcular promedio y desviaci칩n est치ndar de las recompensas\n",
        "average_reward = np.mean(rewards)\n",
        "std_deviation = np.std(rewards)\n",
        "\n",
        "print(f\"Promedio de las recompensas: {average_reward}\")\n",
        "print(f\"Desviaci칩n est치ndar de las recompensas: {std_deviation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq-VAb7ZBksa"
      },
      "source": [
        "El desempe침o de la pol칤tica aleatoria es sub칩ptimo.\n",
        "\n",
        "Esto es, ya que contamos con un promedio de recompensas negativos (-0.3804), indicando m치s p칠rdidas que ganancias, sumado a una alta variabilidad con una desviaci칩n est치ndar de 0.8998, debido a la naturaleza estoc치stica del juego.\n",
        "\n",
        "Con esta pol칤tica, podemos tener un resultado base el cual podemos mejorar, mostrandonos que no es un juego donde una buena estrategia es similar a lanzar una moneda, sino que la estrategia de cu치ndo pedir o cu치ndo quedarse es importante para tener mejores resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEO_dY4x_SJu"
      },
      "source": [
        "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9JsFA1wGmnH",
        "outputId": "73d8c12a-4dfc-4022-e7df-f212f60f5f88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe han truncado las 칰ltimas 5000 l칤neas del flujo de salida.\u001b[0m\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.337    |\n",
            "|    n_updates        | 726      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2272     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3011     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.218    |\n",
            "|    n_updates        | 727      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2276     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3017     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.254    |\n",
            "|    n_updates        | 729      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2280     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3025     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.295    |\n",
            "|    n_updates        | 731      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2284     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3033     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.302    |\n",
            "|    n_updates        | 733      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2288     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3038     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.311    |\n",
            "|    n_updates        | 734      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.16    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2292     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3042     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.301    |\n",
            "|    n_updates        | 735      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.16    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2296     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3048     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.255    |\n",
            "|    n_updates        | 736      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2300     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3054     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.263    |\n",
            "|    n_updates        | 738      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2304     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3061     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.336    |\n",
            "|    n_updates        | 740      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2308     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3066     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.311    |\n",
            "|    n_updates        | 741      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2312     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3071     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.285    |\n",
            "|    n_updates        | 742      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.3     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2316     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3076     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.307    |\n",
            "|    n_updates        | 743      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.29    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2320     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3082     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.259    |\n",
            "|    n_updates        | 745      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.29    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2324     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3088     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.362    |\n",
            "|    n_updates        | 746      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.29    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2328     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3095     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.223    |\n",
            "|    n_updates        | 748      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2332     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3100     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.271    |\n",
            "|    n_updates        | 749      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2336     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3104     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.295    |\n",
            "|    n_updates        | 750      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2340     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3110     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.4      |\n",
            "|    n_updates        | 752      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2344     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3115     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.31     |\n",
            "|    n_updates        | 753      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.21    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2348     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3120     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.289    |\n",
            "|    n_updates        | 754      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2352     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3127     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.333    |\n",
            "|    n_updates        | 756      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2356     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3132     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.254    |\n",
            "|    n_updates        | 757      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.41     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2360     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3137     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.296    |\n",
            "|    n_updates        | 759      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.4      |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2364     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3141     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.329    |\n",
            "|    n_updates        | 760      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.42     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2368     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3148     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.29     |\n",
            "|    n_updates        | 761      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.41     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2372     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3152     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.243    |\n",
            "|    n_updates        | 762      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.4      |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2376     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3157     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.248    |\n",
            "|    n_updates        | 764      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2380     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3163     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.355    |\n",
            "|    n_updates        | 765      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.34     |\n",
            "|    ep_rew_mean      | -0.11    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2384     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 3167     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.33     |\n",
            "|    n_updates        | 766      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.35     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2388     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3173     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.215    |\n",
            "|    n_updates        | 768      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2392     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3180     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.264    |\n",
            "|    n_updates        | 769      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.37     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2396     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3185     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.222    |\n",
            "|    n_updates        | 771      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.35     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2400     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3189     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.353    |\n",
            "|    n_updates        | 772      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.32     |\n",
            "|    ep_rew_mean      | 0.05     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2404     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3193     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.257    |\n",
            "|    n_updates        | 773      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.32     |\n",
            "|    ep_rew_mean      | 0.08     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2408     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3198     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.246    |\n",
            "|    n_updates        | 774      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.31     |\n",
            "|    ep_rew_mean      | 0.08     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2412     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3202     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.236    |\n",
            "|    n_updates        | 775      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.3      |\n",
            "|    ep_rew_mean      | 0.08     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2416     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3206     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.279    |\n",
            "|    n_updates        | 776      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.29     |\n",
            "|    ep_rew_mean      | 0.06     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2420     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3211     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.267    |\n",
            "|    n_updates        | 777      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.31     |\n",
            "|    ep_rew_mean      | 0.06     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2424     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3219     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.288    |\n",
            "|    n_updates        | 779      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.3      |\n",
            "|    ep_rew_mean      | 0.06     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2428     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3225     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.307    |\n",
            "|    n_updates        | 781      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.29     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2432     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3229     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.316    |\n",
            "|    n_updates        | 782      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.32     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2436     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3236     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.284    |\n",
            "|    n_updates        | 783      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.35     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2440     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3245     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.338    |\n",
            "|    n_updates        | 786      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.35     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2444     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3250     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.267    |\n",
            "|    n_updates        | 787      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.36     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2448     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3256     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.292    |\n",
            "|    n_updates        | 788      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.34     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2452     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3261     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.277    |\n",
            "|    n_updates        | 790      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.36     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2456     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3268     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.249    |\n",
            "|    n_updates        | 791      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.35     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2460     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3272     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.286    |\n",
            "|    n_updates        | 792      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.35     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2464     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3276     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.269    |\n",
            "|    n_updates        | 793      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.35     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2468     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3283     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.271    |\n",
            "|    n_updates        | 795      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2472     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3290     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.183    |\n",
            "|    n_updates        | 797      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.37     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2476     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3294     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.274    |\n",
            "|    n_updates        | 798      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.36     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2480     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3299     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.283    |\n",
            "|    n_updates        | 799      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.37     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2484     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3304     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.314    |\n",
            "|    n_updates        | 800      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.35     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2488     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3308     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.281    |\n",
            "|    n_updates        | 801      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.34     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2492     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3314     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.242    |\n",
            "|    n_updates        | 803      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.37     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2496     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3322     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.292    |\n",
            "|    n_updates        | 805      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2500     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3327     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.341    |\n",
            "|    n_updates        | 806      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.4      |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2504     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3333     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.265    |\n",
            "|    n_updates        | 808      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.39     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2508     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3337     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.274    |\n",
            "|    n_updates        | 809      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.41     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2512     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3343     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.314    |\n",
            "|    n_updates        | 810      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2516     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3349     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.186    |\n",
            "|    n_updates        | 812      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.42     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2520     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3353     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.262    |\n",
            "|    n_updates        | 813      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.16    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2524     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3357     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.317    |\n",
            "|    n_updates        | 814      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.39     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2528     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3364     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.273    |\n",
            "|    n_updates        | 815      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.42     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2532     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3371     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.321    |\n",
            "|    n_updates        | 817      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.4      |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2536     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3376     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.26     |\n",
            "|    n_updates        | 818      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.4      |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2540     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3385     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.325    |\n",
            "|    n_updates        | 821      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.42     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2544     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3392     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.182    |\n",
            "|    n_updates        | 822      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.4      |\n",
            "|    ep_rew_mean      | -0.16    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2548     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3396     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.245    |\n",
            "|    n_updates        | 823      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.41     |\n",
            "|    ep_rew_mean      | -0.16    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2552     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3402     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.215    |\n",
            "|    n_updates        | 825      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.4      |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2556     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3408     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.223    |\n",
            "|    n_updates        | 826      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.41     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2560     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3413     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.218    |\n",
            "|    n_updates        | 828      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.41     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2564     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3417     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.292    |\n",
            "|    n_updates        | 829      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.39     |\n",
            "|    ep_rew_mean      | -0.21    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2568     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3422     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.315    |\n",
            "|    n_updates        | 830      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.21    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2572     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3428     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.366    |\n",
            "|    n_updates        | 831      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.41     |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2576     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3435     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.311    |\n",
            "|    n_updates        | 833      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2580     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3442     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.25     |\n",
            "|    n_updates        | 835      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.42     |\n",
            "|    ep_rew_mean      | -0.11    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2584     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3446     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.23     |\n",
            "|    n_updates        | 836      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.11    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2588     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3453     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.349    |\n",
            "|    n_updates        | 838      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.44     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2592     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3458     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.299    |\n",
            "|    n_updates        | 839      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.4      |\n",
            "|    ep_rew_mean      | -0.16    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2596     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3462     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.261    |\n",
            "|    n_updates        | 840      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2600     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3470     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.31     |\n",
            "|    n_updates        | 842      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2604     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3476     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.322    |\n",
            "|    n_updates        | 843      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.44     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2608     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3481     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.233    |\n",
            "|    n_updates        | 845      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2612     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3489     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.204    |\n",
            "|    n_updates        | 847      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.44     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2616     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3493     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.22     |\n",
            "|    n_updates        | 848      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2620     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3500     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.208    |\n",
            "|    n_updates        | 849      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2624     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3504     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.244    |\n",
            "|    n_updates        | 850      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2628     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3509     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.241    |\n",
            "|    n_updates        | 852      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2632     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3514     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 853      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2636     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3522     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.27     |\n",
            "|    n_updates        | 855      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.42     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2640     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3527     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.269    |\n",
            "|    n_updates        | 856      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.44     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2644     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3536     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.286    |\n",
            "|    n_updates        | 858      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2648     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3541     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.275    |\n",
            "|    n_updates        | 860      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2652     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3549     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.269    |\n",
            "|    n_updates        | 862      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2656     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3555     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.254    |\n",
            "|    n_updates        | 863      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2660     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3563     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.231    |\n",
            "|    n_updates        | 865      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2664     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3568     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.245    |\n",
            "|    n_updates        | 866      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2668     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3574     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.302    |\n",
            "|    n_updates        | 868      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.11    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2672     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3578     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.22     |\n",
            "|    n_updates        | 869      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2676     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3582     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.241    |\n",
            "|    n_updates        | 870      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2680     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3591     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.231    |\n",
            "|    n_updates        | 872      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2684     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3597     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.284    |\n",
            "|    n_updates        | 874      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2688     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3603     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.314    |\n",
            "|    n_updates        | 875      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2692     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3609     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.289    |\n",
            "|    n_updates        | 877      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2696     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3618     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.31     |\n",
            "|    n_updates        | 879      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2700     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3622     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.187    |\n",
            "|    n_updates        | 880      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2704     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3627     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.236    |\n",
            "|    n_updates        | 881      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2708     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3634     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.3      |\n",
            "|    n_updates        | 883      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.26    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2712     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3640     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.306    |\n",
            "|    n_updates        | 884      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2716     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3651     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 887      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.28    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2720     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3655     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.229    |\n",
            "|    n_updates        | 888      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.34    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2724     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3661     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.29     |\n",
            "|    n_updates        | 890      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.3     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2728     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3668     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.249    |\n",
            "|    n_updates        | 891      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.29    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2732     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3674     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.196    |\n",
            "|    n_updates        | 893      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.28    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2736     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3678     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 894      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2740     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3689     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.264    |\n",
            "|    n_updates        | 897      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.26    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2744     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3694     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.235    |\n",
            "|    n_updates        | 898      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.23    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2748     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3698     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.26     |\n",
            "|    n_updates        | 899      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2752     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3702     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.285    |\n",
            "|    n_updates        | 900      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2756     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3706     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.219    |\n",
            "|    n_updates        | 901      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2760     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3710     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.169    |\n",
            "|    n_updates        | 902      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.27    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2764     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3715     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.33     |\n",
            "|    n_updates        | 903      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.3     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2768     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3722     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.338    |\n",
            "|    n_updates        | 905      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.32    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2772     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3726     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.275    |\n",
            "|    n_updates        | 906      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.27    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2776     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3732     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.178    |\n",
            "|    n_updates        | 907      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.27    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2780     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3738     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.251    |\n",
            "|    n_updates        | 909      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.33    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2784     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3744     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.28     |\n",
            "|    n_updates        | 910      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.3     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2788     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3750     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.285    |\n",
            "|    n_updates        | 912      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.34    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2792     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3756     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.23     |\n",
            "|    n_updates        | 913      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | -0.36    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2796     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3761     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.31     |\n",
            "|    n_updates        | 915      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.35    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2800     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3770     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.302    |\n",
            "|    n_updates        | 917      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.35    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2804     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3774     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.288    |\n",
            "|    n_updates        | 918      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.44     |\n",
            "|    ep_rew_mean      | -0.3     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2808     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3778     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.329    |\n",
            "|    n_updates        | 919      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.42     |\n",
            "|    ep_rew_mean      | -0.28    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2812     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3782     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.278    |\n",
            "|    n_updates        | 920      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.36     |\n",
            "|    ep_rew_mean      | -0.26    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2816     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3787     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.224    |\n",
            "|    n_updates        | 921      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.23    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2820     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3793     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.206    |\n",
            "|    n_updates        | 923      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.37     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2824     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3798     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.26     |\n",
            "|    n_updates        | 924      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.35     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2828     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3803     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.284    |\n",
            "|    n_updates        | 925      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.35     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2832     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3809     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.21     |\n",
            "|    n_updates        | 927      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2836     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3816     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.344    |\n",
            "|    n_updates        | 928      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.33     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2840     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3822     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.345    |\n",
            "|    n_updates        | 930      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.33     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2844     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3827     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.299    |\n",
            "|    n_updates        | 931      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.33     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2848     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3831     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.223    |\n",
            "|    n_updates        | 932      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.37     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2852     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3839     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.264    |\n",
            "|    n_updates        | 934      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.11    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2856     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3844     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.259    |\n",
            "|    n_updates        | 935      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.42     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2860     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3852     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.249    |\n",
            "|    n_updates        | 937      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.44     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2864     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3859     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.228    |\n",
            "|    n_updates        | 939      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.42     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2868     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3864     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.289    |\n",
            "|    n_updates        | 940      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2872     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3871     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.34     |\n",
            "|    n_updates        | 942      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.44     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2876     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3876     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.296    |\n",
            "|    n_updates        | 943      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | -0.16    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2880     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3881     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.205    |\n",
            "|    n_updates        | 945      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.11    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2884     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3890     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.287    |\n",
            "|    n_updates        | 947      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2888     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3896     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.26     |\n",
            "|    n_updates        | 948      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.11    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2892     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3901     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.22     |\n",
            "|    n_updates        | 950      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2896     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3911     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.211    |\n",
            "|    n_updates        | 952      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2900     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3917     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.315    |\n",
            "|    n_updates        | 954      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2904     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3923     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.179    |\n",
            "|    n_updates        | 955      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2908     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3930     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.384    |\n",
            "|    n_updates        | 957      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2912     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3937     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.266    |\n",
            "|    n_updates        | 959      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2916     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3944     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.204    |\n",
            "|    n_updates        | 960      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2920     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3950     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.281    |\n",
            "|    n_updates        | 962      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2924     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3957     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.237    |\n",
            "|    n_updates        | 964      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2928     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3963     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.276    |\n",
            "|    n_updates        | 965      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2932     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3968     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.223    |\n",
            "|    n_updates        | 966      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.16    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2936     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3975     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.331    |\n",
            "|    n_updates        | 968      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2940     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3979     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.295    |\n",
            "|    n_updates        | 969      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2944     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3987     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.318    |\n",
            "|    n_updates        | 971      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2948     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 3993     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.267    |\n",
            "|    n_updates        | 973      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2952     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 4001     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.244    |\n",
            "|    n_updates        | 975      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.21    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2956     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 4006     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.209    |\n",
            "|    n_updates        | 976      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2960     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 4011     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.272    |\n",
            "|    n_updates        | 977      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2964     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4017     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.349    |\n",
            "|    n_updates        | 979      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2968     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4022     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.202    |\n",
            "|    n_updates        | 980      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.21    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2972     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4029     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.267    |\n",
            "|    n_updates        | 982      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.23    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2976     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4035     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.207    |\n",
            "|    n_updates        | 983      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.21    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2980     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4042     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.242    |\n",
            "|    n_updates        | 985      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2984     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4049     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.275    |\n",
            "|    n_updates        | 987      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2988     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4057     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.195    |\n",
            "|    n_updates        | 989      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2992     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4064     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.28     |\n",
            "|    n_updates        | 990      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2996     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4069     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.238    |\n",
            "|    n_updates        | 992      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.21    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3000     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4076     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.23     |\n",
            "|    n_updates        | 993      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.27    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3004     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4080     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.214    |\n",
            "|    n_updates        | 994      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.29    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3008     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4084     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.191    |\n",
            "|    n_updates        | 995      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3012     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4093     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.226    |\n",
            "|    n_updates        | 998      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.23    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3016     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4097     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.263    |\n",
            "|    n_updates        | 999      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3020     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4104     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.187    |\n",
            "|    n_updates        | 1000     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3024     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4111     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.234    |\n",
            "|    n_updates        | 1002     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3028     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4115     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.199    |\n",
            "|    n_updates        | 1003     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3032     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4121     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.304    |\n",
            "|    n_updates        | 1005     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3036     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4126     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.313    |\n",
            "|    n_updates        | 1006     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3040     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4133     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.26     |\n",
            "|    n_updates        | 1008     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.21    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3044     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4138     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.2      |\n",
            "|    n_updates        | 1009     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.23    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3048     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4145     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.313    |\n",
            "|    n_updates        | 1011     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.26    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3052     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4151     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 1012     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3056     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4155     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.205    |\n",
            "|    n_updates        | 1013     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3060     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4160     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 1014     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3064     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4164     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.215    |\n",
            "|    n_updates        | 1015     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3068     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4169     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.223    |\n",
            "|    n_updates        | 1017     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3072     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4175     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.248    |\n",
            "|    n_updates        | 1018     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3076     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4182     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.183    |\n",
            "|    n_updates        | 1020     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3080     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4189     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.317    |\n",
            "|    n_updates        | 1022     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3084     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4194     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 1023     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.44     |\n",
            "|    ep_rew_mean      | -0.23    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3088     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4201     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.298    |\n",
            "|    n_updates        | 1025     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.23    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3092     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4209     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.273    |\n",
            "|    n_updates        | 1027     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3096     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4215     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.191    |\n",
            "|    n_updates        | 1028     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3100     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4221     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.214    |\n",
            "|    n_updates        | 1030     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3104     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4229     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.237    |\n",
            "|    n_updates        | 1032     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3108     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4234     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.33     |\n",
            "|    n_updates        | 1033     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3112     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4240     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.276    |\n",
            "|    n_updates        | 1034     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3116     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4245     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.287    |\n",
            "|    n_updates        | 1036     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3120     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4252     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.195    |\n",
            "|    n_updates        | 1037     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3124     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4257     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.23     |\n",
            "|    n_updates        | 1039     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3128     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4262     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 1040     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3132     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4270     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.32     |\n",
            "|    n_updates        | 1042     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3136     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4275     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.313    |\n",
            "|    n_updates        | 1043     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3140     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4283     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.199    |\n",
            "|    n_updates        | 1045     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3144     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4295     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.271    |\n",
            "|    n_updates        | 1048     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3148     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4300     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.255    |\n",
            "|    n_updates        | 1049     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3152     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 4306     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.262    |\n",
            "|    n_updates        | 1051     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3156     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4313     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.292    |\n",
            "|    n_updates        | 1053     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3160     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4323     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.237    |\n",
            "|    n_updates        | 1055     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3164     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4328     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.293    |\n",
            "|    n_updates        | 1056     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.65     |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3168     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4334     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.261    |\n",
            "|    n_updates        | 1058     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.68     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3172     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4343     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.21     |\n",
            "|    n_updates        | 1060     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.67     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3176     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4349     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.267    |\n",
            "|    n_updates        | 1062     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.65     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3180     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4354     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.168    |\n",
            "|    n_updates        | 1063     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.66     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3184     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4360     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.295    |\n",
            "|    n_updates        | 1064     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.67     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3188     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4368     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.247    |\n",
            "|    n_updates        | 1066     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.67     |\n",
            "|    ep_rew_mean      | -0.11    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3192     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4376     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.214    |\n",
            "|    n_updates        | 1068     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.68     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3196     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4383     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.228    |\n",
            "|    n_updates        | 1070     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.68     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3200     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4389     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.333    |\n",
            "|    n_updates        | 1072     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.65     |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3204     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4394     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.245    |\n",
            "|    n_updates        | 1073     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.66     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3208     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4400     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.2      |\n",
            "|    n_updates        | 1074     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3212     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4404     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.237    |\n",
            "|    n_updates        | 1075     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.66     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3216     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4411     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.255    |\n",
            "|    n_updates        | 1077     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3220     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4415     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.249    |\n",
            "|    n_updates        | 1078     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3224     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4420     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.185    |\n",
            "|    n_updates        | 1079     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3228     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4425     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.236    |\n",
            "|    n_updates        | 1081     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3232     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4431     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.306    |\n",
            "|    n_updates        | 1082     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3236     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4437     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.241    |\n",
            "|    n_updates        | 1084     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3240     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4447     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.292    |\n",
            "|    n_updates        | 1086     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3244     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4454     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.24     |\n",
            "|    n_updates        | 1088     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3248     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4462     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.195    |\n",
            "|    n_updates        | 1090     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3252     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4467     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.339    |\n",
            "|    n_updates        | 1091     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3256     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4473     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.245    |\n",
            "|    n_updates        | 1093     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.11    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3260     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4479     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.276    |\n",
            "|    n_updates        | 1094     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3264     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4484     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.254    |\n",
            "|    n_updates        | 1095     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3268     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4492     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.29     |\n",
            "|    n_updates        | 1097     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3272     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4497     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.172    |\n",
            "|    n_updates        | 1099     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3276     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4503     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.211    |\n",
            "|    n_updates        | 1100     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3280     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4511     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.248    |\n",
            "|    n_updates        | 1102     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3284     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4516     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.234    |\n",
            "|    n_updates        | 1103     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3288     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4522     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.273    |\n",
            "|    n_updates        | 1105     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3292     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4527     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.31     |\n",
            "|    n_updates        | 1106     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3296     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4537     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.252    |\n",
            "|    n_updates        | 1109     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3300     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4542     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.26     |\n",
            "|    n_updates        | 1110     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3304     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4546     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.211    |\n",
            "|    n_updates        | 1111     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3308     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4554     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.238    |\n",
            "|    n_updates        | 1113     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3312     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4561     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.226    |\n",
            "|    n_updates        | 1115     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3316     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4565     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.266    |\n",
            "|    n_updates        | 1116     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3320     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4572     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.331    |\n",
            "|    n_updates        | 1117     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3324     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4579     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.192    |\n",
            "|    n_updates        | 1119     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3328     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4586     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.196    |\n",
            "|    n_updates        | 1121     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3332     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4592     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.294    |\n",
            "|    n_updates        | 1122     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3336     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4598     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.303    |\n",
            "|    n_updates        | 1124     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3340     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4606     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.218    |\n",
            "|    n_updates        | 1126     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3344     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4612     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.192    |\n",
            "|    n_updates        | 1127     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.06     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3348     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 4617     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.214    |\n",
            "|    n_updates        | 1129     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.07     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3352     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4622     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.245    |\n",
            "|    n_updates        | 1130     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.06     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3356     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4630     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.247    |\n",
            "|    n_updates        | 1132     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.06     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3360     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4637     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.211    |\n",
            "|    n_updates        | 1134     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3364     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4644     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.291    |\n",
            "|    n_updates        | 1135     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3368     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4648     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 1136     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.05     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3372     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4655     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.286    |\n",
            "|    n_updates        | 1138     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.09     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3376     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4660     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.234    |\n",
            "|    n_updates        | 1139     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.09     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3380     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4664     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.242    |\n",
            "|    n_updates        | 1140     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.07     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3384     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4669     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.346    |\n",
            "|    n_updates        | 1142     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.09     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3388     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4678     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 1144     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.07     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3392     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4685     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.322    |\n",
            "|    n_updates        | 1146     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3396     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4693     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.298    |\n",
            "|    n_updates        | 1148     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3400     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4698     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.244    |\n",
            "|    n_updates        | 1149     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3404     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4705     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.321    |\n",
            "|    n_updates        | 1151     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3408     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4709     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.185    |\n",
            "|    n_updates        | 1152     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3412     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4715     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.329    |\n",
            "|    n_updates        | 1153     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3416     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4723     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.277    |\n",
            "|    n_updates        | 1155     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3420     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4731     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.296    |\n",
            "|    n_updates        | 1157     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3424     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4738     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.26     |\n",
            "|    n_updates        | 1159     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3428     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4744     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.163    |\n",
            "|    n_updates        | 1160     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3432     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4754     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.266    |\n",
            "|    n_updates        | 1163     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3436     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4758     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.251    |\n",
            "|    n_updates        | 1164     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3440     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4763     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.307    |\n",
            "|    n_updates        | 1165     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3444     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4769     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.294    |\n",
            "|    n_updates        | 1167     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3448     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4774     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.197    |\n",
            "|    n_updates        | 1168     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3452     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4780     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.219    |\n",
            "|    n_updates        | 1169     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3456     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4787     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.191    |\n",
            "|    n_updates        | 1171     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3460     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4793     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 1173     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3464     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4801     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.232    |\n",
            "|    n_updates        | 1175     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3468     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4806     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 1176     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3472     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4810     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.258    |\n",
            "|    n_updates        | 1177     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3476     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4814     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.319    |\n",
            "|    n_updates        | 1178     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3480     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4820     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.182    |\n",
            "|    n_updates        | 1179     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3484     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4825     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.282    |\n",
            "|    n_updates        | 1181     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3488     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4830     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.306    |\n",
            "|    n_updates        | 1182     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3492     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4836     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.25     |\n",
            "|    n_updates        | 1183     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3496     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4844     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.287    |\n",
            "|    n_updates        | 1185     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3500     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4851     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.143    |\n",
            "|    n_updates        | 1187     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3504     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4858     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.242    |\n",
            "|    n_updates        | 1189     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3508     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4866     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.193    |\n",
            "|    n_updates        | 1191     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3512     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4873     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.321    |\n",
            "|    n_updates        | 1193     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3516     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4879     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.241    |\n",
            "|    n_updates        | 1194     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3520     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4884     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.194    |\n",
            "|    n_updates        | 1195     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3524     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4889     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.227    |\n",
            "|    n_updates        | 1197     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3528     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4893     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.325    |\n",
            "|    n_updates        | 1198     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.44     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3532     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4898     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.271    |\n",
            "|    n_updates        | 1199     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3536     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4907     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 1201     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3540     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 4912     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.238    |\n",
            "|    n_updates        | 1202     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3544     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4917     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.172    |\n",
            "|    n_updates        | 1204     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3548     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4924     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.329    |\n",
            "|    n_updates        | 1205     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3552     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4930     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.234    |\n",
            "|    n_updates        | 1207     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3556     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4937     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.27     |\n",
            "|    n_updates        | 1209     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3560     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4943     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.219    |\n",
            "|    n_updates        | 1210     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3564     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4948     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.205    |\n",
            "|    n_updates        | 1211     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3568     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4952     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.19     |\n",
            "|    n_updates        | 1212     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3572     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4958     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.207    |\n",
            "|    n_updates        | 1214     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3576     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4964     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.3      |\n",
            "|    n_updates        | 1215     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3580     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4970     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.242    |\n",
            "|    n_updates        | 1217     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3584     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4974     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.256    |\n",
            "|    n_updates        | 1218     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3588     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4979     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.271    |\n",
            "|    n_updates        | 1219     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3592     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4985     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.169    |\n",
            "|    n_updates        | 1221     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3596     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4992     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.177    |\n",
            "|    n_updates        | 1222     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3600     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 4998     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.193    |\n",
            "|    n_updates        | 1224     |\n",
            "----------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.dqn.dqn.DQN at 0x7cafab4697b0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from stable_baselines3 import DQN\n",
        "\n",
        "# Crear el modelo DQN\n",
        "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.learn(total_timesteps=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-bpdb8wZID1"
      },
      "source": [
        "#### **1.1.4 Evaluaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. 쮺칩mo es el performance de su agente? 쮼s mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-d7d8GFf7F6",
        "outputId": "ed9c4288-5793-4899-efc5-faa497ba276e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparaci칩n de resultados:\n",
            "Pol칤tica Aleatoria \n",
            "Promedio: -0.3976, Desviaci칩n: 0.8948263742201612\n",
            "Pol칤tica DQN \n",
            "Promedio: -0.085, Desviaci칩n: 0.9462425693235325\n"
          ]
        }
      ],
      "source": [
        "# Evaluar la pol칤tica aprendida por DQN\n",
        "dqn_rewards = []\n",
        "\n",
        "for _ in range(n):\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total = 0\n",
        "\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)  # Pol칤tica DQN\n",
        "        obs, reward, done, _, _ = env.step(action)\n",
        "        total += reward\n",
        "\n",
        "    dqn_rewards.append(total)\n",
        "\n",
        "# Calcular promedio y desviaci칩n est치ndar de la pol칤tica DQN\n",
        "average_dqn_reward = np.mean(dqn_rewards)\n",
        "std_dqn_deviation = np.std(dqn_rewards)\n",
        "\n",
        "# Comparar resultados\n",
        "print(\"Comparaci칩n de resultados:\")\n",
        "print(f\"Pol칤tica Aleatoria \\nPromedio: {average_reward}, Desviaci칩n: {std_deviation}\")\n",
        "print(f\"Pol칤tica DQN \\nPromedio: {average_dqn_reward}, Desviaci칩n: {std_dqn_deviation}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLVoKZq_Hz_e"
      },
      "source": [
        "Podemos ver que el desempe침o del agente mejora considerablemente en cuanto el promedio de sus recompensas, subiendo de su promedio de a -0.1018, tomando deciciones estrat칠gicas e inteligentes y con ello ganando m치s veces en promedio que tomando deciciones al azar.\n",
        "\n",
        "Sin embargo, podemos ver tambi칠n que el desempe침o del agente tiene m치s variabilidad en sus resultados con su pol칤tica, lo cual nos indica que puede ser refinado para mejorar su toma de decisiones.\n",
        "\n",
        "Con lo anterior, este escenario es mejor al baseline, pero ser칤a recomendable seguir mejorando su consistencia en el desempe침o.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-EsAaPAYEm"
      },
      "source": [
        "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "Genere una funci칩n que reciba un estado y retorne la accion del agente. Luego, use esta funci칩n para entregar la acci칩n escogida frente a los siguientes escenarios:\n",
        "\n",
        "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "쯉on coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: 쮸 que clase de python pertenecen los estados? Pruebe a usar el m칠todo `.reset` para saberlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Fh8XlGyzwtRp"
      },
      "outputs": [],
      "source": [
        "def elegir_accion(estado, model):\n",
        "    action, _ = model.predict(estado, deterministic=True)\n",
        "    return action\n",
        "\n",
        "estado1 = [6, 7, False]\n",
        "accion1 = elegir_accion(estado1, model)\n",
        "\n",
        "estado2 = [19, 3, True]\n",
        "accion2 = elegir_accion(estado2, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOkRbjLULS03",
        "outputId": "b9286ba9-0525-46fa-d4f9-4184dd304bf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acci칩n para el estado 1 (6, 7, sin as): Pedir carta\n"
          ]
        }
      ],
      "source": [
        "estado_1 = [6, 7, False]\n",
        "accion_1 = elegir_accion(estado_1, model)\n",
        "\n",
        "print(f\"Acci칩n para el estado 1 (6, 7, sin as): {'Pedir carta' if accion_1 == 1 else 'Quedarse'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BeKEBC9LwiE",
        "outputId": "10525308-26c0-47c7-c5e8-6e646c2495d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acci칩n para el estado 2 (19, 3, con as): Quedarse\n"
          ]
        }
      ],
      "source": [
        "estado_2 = [19, 3, True]\n",
        "accion_2 = elegir_accion(estado_2, model)\n",
        "\n",
        "print(f\"Acci칩n para el estado 2 (19, 3, con as): {'Pedir carta' if accion_2 == 1 else 'Quedarse'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P9QvGS0SIDw"
      },
      "source": [
        "Tanto el estado 1 como el estado 2 parecen ser coherentes con las reglas del juego.\n",
        "\n",
        "Esto es porque la suma en el primer caso del agente es muy baja y ser칤a normal pedir una sigiente carta (si no pedimos, perdemos directamente de hecho), mientras que en el estado 2 la suma del jugador es muy alta y seguramente sobrepase el 21 (y actualmente, la carta que tiene el dealer es muy baja).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqCTqqroh03"
      },
      "source": [
        "### **1.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci칩n 2.1, en esta secci칩n usted se encargar치 de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
        "\n",
        "Comencemos preparando el ambiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvQUyuZ_FtZ4",
        "outputId": "b0a8ac67-86f7-441d-acc8-b2146390b8ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\", continuous = True) # notar el par치metro continuous = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBU4lGX3wpN6"
      },
      "source": [
        "Noten que se especifica el par치metro `continuous = True`. 쯈ue implicancias tiene esto sobre el ambiente?\n",
        "\n",
        "Adem치s, se le facilita la funci칩n `export_gif` para el ejercicio 2.2.4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRiWpSo9yfr9",
        "outputId": "38f87a3b-8a34-4c2a-b961-e54e0c71ac07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  funci칩n que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fspIIHOtXfH8"
      },
      "source": [
        "El par치metro continuous=True transforma el problema en un desaf칤o m치s complejo al permitir un control m치s detallado del lander, lo cual tambi칠n requiere m칠todos de aprendizaje m치s sofisticados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk5VJVppXh3N"
      },
      "source": [
        "#### **1.2.1 Descripci칩n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci칩n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci칩n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. 쮺omo se distinguen las acciones de este ambiente en comparaci칩n a `Blackjack`?\n",
        "\n",
        "Nota: recuerde que se especific칩 el par치metro `continuous = True`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb-u9LUE8O9a"
      },
      "source": [
        "El ambiente de LunarLander consiste en un problema de control de trayectoria de un cohete, donde el objetivo es aterrizar en una plataforma sin salir del 치rea designada ni estrellarse. La formulaci칩n en MDP corresponde a:\n",
        "\n",
        "* Estados:\n",
        "  - Coordenadas x e y del lander (posici칩n relativa al 치rea de aterrizaje).\n",
        "  - Velocidades lineales en x e y.\n",
        "  - 츼ngulo de orientaci칩n del lander.\n",
        "  - Velocidad angular.\n",
        "  - Contacto de las patas con el suelo (dos valores booleanos).\n",
        "\n",
        "* Acciones:\n",
        "  - 0: No realizar ninguna acci칩n.\n",
        "  - 1: Activar el motor lateral izquierdo.\n",
        "  - 2: Activar el motor principal.\n",
        "  - 3: Activar el motor lateral derecho.\n",
        "\n",
        "* Recompensas:\n",
        "- Proximidad al 치rea de aterrizaje: Incrementos/penalizaciones por acercarse/alejarse.\n",
        "- Velocidad y orientaci칩n:\n",
        "  - Penalizaci칩n por velocidades altas y 치ngulos inadecuados.\n",
        "- Uso de motores:\n",
        "  - Penalizaci칩n por activaciones de motores -0,03 para laterales y -0,3 para el principal.\n",
        "- Aterrizajes:\n",
        "  - Recompensa de +10 por cada pata en contacto con el suelo.\n",
        "  - Recompensa de +100 por un aterrizaje exitoso.\n",
        "  - Penalizaci칩n de -100 por estrellarse.\n",
        "  - Un episodio se considera resuelto si el agente acumula al menos 200 puntos.\n",
        "\n",
        "**Diferencia de acciones con Blackjack**:\n",
        "\n",
        "A diferencia de Blackjack, donde las acciones son discretas y binarias (pedir o quedarse), en LunarLander las acciones pueden ser discretas (selecci칩n de motores) o **continuas** (intensidad de empuje), dependiendo de la configuraci칩n del ambiente. Adem치s, los estados en LunarLander son multidimensionales y continuos, mientras que en Blackjack los estados son valores discretos relacionados con la suma de cartas y las cartas visibles del dealer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YChodtNQwzG2"
      },
      "source": [
        "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci칩n 10 veces y reporte el promedio y desviaci칩n de las recompensas. 쮺칩mo calificar칤a el performance de esta pol칤tica?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bwc3A0GX7a8",
        "outputId": "a1785b3b-9157-4d1f-8e6c-ba4f91f041e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Promedio de las recompensas: -196.71937466563483\n",
            "Desviaci칩n est치ndar de las recompensas: 106.71999812709856\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "# Variables para almacenar resultados\n",
        "rewards = []\n",
        "n = 10  # n칰mero de repeticiones\n",
        "\n",
        "# Simulaci칩n de 10 episodios con acciones aleatorias\n",
        "for _ in range(n):\n",
        "    obs = env.reset()  # Reiniciar el ambiente\n",
        "    done = False\n",
        "    total = 0\n",
        "\n",
        "    while not done:\n",
        "        action = env.action_space.sample()  # Seleccionar una acci칩n aleatoria\n",
        "        obs, reward, done, _, _ = env.step(action)  # Ejecutar la acci칩n\n",
        "        total += reward\n",
        "\n",
        "    rewards.append(total)\n",
        "\n",
        "# Calcular promedio y desviaci칩n est치ndar de las recompensas\n",
        "average_reward = np.mean(rewards)\n",
        "std_deviation = np.std(rewards)\n",
        "\n",
        "print(f\"Promedio de las recompensas: {average_reward}\")\n",
        "print(f\"Desviaci칩n est치ndar de las recompensas: {std_deviation}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf5HBRLRZq3h"
      },
      "source": [
        "El rendimiento de esta pol칤tica aleatoria nuevamente es sub칩ptima como es esperado.\n",
        "\n",
        "Podemos ver que en promedio se estrella el lander m치s de 2 veces por aterrizaje, lo cual es un muy mal desempe침o para lo que queremos y que tiene una desviaci칩n est치ndar muy alta de sus recompenzas, con un valor de 125.\n",
        "\n",
        "Claramente hay espacio de mejora y lo desarrollaremos a continuaci칩n:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQrZVQflX_5f"
      },
      "source": [
        "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_6Ia9uoF7Hs",
        "outputId": "e28152bc-ef69-4c37-d18b-8ed14cd9f564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 115      |\n",
            "|    ep_rew_mean     | -259     |\n",
            "| time/              |          |\n",
            "|    fps             | 812      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 120          |\n",
            "|    ep_rew_mean          | -222         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 630          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 6            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042378837 |\n",
            "|    clip_fraction        | 0.0248       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.0052      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 925          |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00321     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 1.9e+03      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 120          |\n",
            "|    ep_rew_mean          | -221         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 562          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039167763 |\n",
            "|    clip_fraction        | 0.0181       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.0222      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 375          |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00438     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 1.1e+03      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 124          |\n",
            "|    ep_rew_mean          | -223         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 528          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 15           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054072086 |\n",
            "|    clip_fraction        | 0.0357       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.00907     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 469          |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00615     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 995          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 125         |\n",
            "|    ep_rew_mean          | -207        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 523         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005671428 |\n",
            "|    clip_fraction        | 0.0411      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.86       |\n",
            "|    explained_variance   | -0.0114     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 511         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00736    |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 929         |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7cae813bfa00>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "# Crear el modelo PPO\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.learn(total_timesteps=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z-oIUSrlAsY"
      },
      "source": [
        "#### **1.2.4 Evaluaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. 쮺칩mo es el performance de su agente? 쮼s mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ophyU3KrWrwl",
        "outputId": "323f76c6-d17e-4d5a-acda-e207173eadf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparaci칩n de resultados:\n",
            "Pol칤tica Aleatoria \n",
            "Promedio: -196.71937466563483, Desviaci칩n: 106.71999812709856\n",
            "Pol칤tica PPO \n",
            "Promedio: -130.06086324494504, Desviaci칩n: 69.51122552581967\n"
          ]
        }
      ],
      "source": [
        "# Evaluar la pol칤tica aprendida por PPO\n",
        "ppo_rewards = []\n",
        "\n",
        "for _ in range(n):\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total = 0\n",
        "\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)  # Pol칤tica PPO\n",
        "        obs, reward, done, _, _ = env.step(action)\n",
        "        total += reward\n",
        "\n",
        "    ppo_rewards.append(total)\n",
        "\n",
        "# Calcular promedio y desviaci칩n est치ndar de la pol칤tica PPO\n",
        "average_ppo_reward = np.mean(ppo_rewards)\n",
        "std_ppo_deviation = np.std(ppo_rewards)\n",
        "\n",
        "# Comparar resultados\n",
        "print(\"Comparaci칩n de resultados:\")\n",
        "print(f\"Pol칤tica Aleatoria \\nPromedio: {average_reward}, Desviaci칩n: {std_deviation}\")\n",
        "print(f\"Pol칤tica PPO \\nPromedio: {average_ppo_reward}, Desviaci칩n: {std_ppo_deviation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qf8TctocMme"
      },
      "source": [
        "El performance de la gente nuevamente mejora, pero no de manera tan sustancial como en el caso del blackjack. En este caso, podemos ver que en promedio se estrella 1 vez el lander en vez de 2, lo cual es bueno, pero no 칩ptimo. Adem치s, viendo su desviaci칩n, este resultado es m치s consistente en el tiempo. Con esto, tenemos un mejor modelo que el baseline, pero con espacio a mejora."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      },
      "source": [
        "#### **1.2.5 Optimizaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par치metros como:\n",
        "- `total_timesteps`\n",
        "- `learning_rate`\n",
        "- `batch_size`\n",
        "\n",
        "Una vez optimizado el modelo, use la funci칩n `export_gif` para estudiar el comportamiento de su agente en la resoluci칩n del ambiente y comente sobre sus resultados.\n",
        "\n",
        "Adjunte el gif generado en su entrega (mejor a칰n si adem치s adjuntan el gif en el markdown)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aItYF6sr6F_6"
      },
      "outputs": [],
      "source": [
        "model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate = 0.0001, batch_size = 32, seed = 123)\n",
        "model.learn(total_timesteps = 500000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNE6YRKhi730"
      },
      "outputs": [],
      "source": [
        "# Evaluar la pol칤tica aprendida por PPO\n",
        "ppo_opt_rewards = []\n",
        "\n",
        "for _ in range(n):\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total = 0\n",
        "\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)  # Pol칤tica PPO\n",
        "        obs, reward, done, _, _ = env.step(action)\n",
        "        total += reward\n",
        "\n",
        "    ppo_opt_rewards.append(total)\n",
        "\n",
        "# Calcular promedio y desviaci칩n est치ndar de la pol칤tica PPO\n",
        "average_ppo_opt_reward = np.mean(ppo_opt_rewards)\n",
        "std_ppo_opt_deviation = np.std(ppo_opt_rewards)\n",
        "\n",
        "# Comparar resultados\n",
        "print(\"Comparaci칩n de resultados:\")\n",
        "print(f\"Pol칤tica Aleatoria \\nPromedio: {average_reward}, Desviaci칩n: {std_deviation}\")\n",
        "print(f\"Pol칤tica PPO \\nPromedio: {average_ppo_reward}, Desviaci칩n: {std_ppo_deviation}\")\n",
        "print(f\"Pol칤tica PPO Optimizado \\nPromedio: {average_ppo_opt_reward}, Desviaci칩n: {std_ppo_opt_deviation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUy0eUMrjXZZ"
      },
      "outputs": [],
      "source": [
        "export_gif(model, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRO_jMeuje2u"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(open('agent_performance.gif','rb').read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPUY-Ktgf2BO"
      },
      "source": [
        "## **2. Large Language Models (4.0 puntos)**\n",
        "\n",
        "En esta secci칩n se enfocar치n en habilitar un Chatbot que nos permita responder preguntas 칰tiles a trav칠s de LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ4fPRRihGLe"
      },
      "source": [
        "### **2.0 Configuraci칩n Inicial**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Como siempre, cargamos todas nuestras API KEY al entorno:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud2Xm_k-hFJn"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
        "\n",
        "if \"TAVILY_API_KEY\" not in os.environ:\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj9JvQUsgZZJ"
      },
      "source": [
        "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsecci칩n es que habiliten un chatbot que pueda responder preguntas usando informaci칩n contenida en documentos PDF a trav칠s de **Retrieval Augmented Generation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxOQroVnaZ5"
      },
      "source": [
        "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
        "\n",
        "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
        "  - 2 documentos .pdf como m칤nimo.\n",
        "  - 50 p치ginas de contenido como m칤nimo entre todos los documentos.\n",
        "  - Ideas para documentos: Documentos relacionados a temas acad칠micos, laborales o de ocio. Aprovechen este ejercicio para construir algo 칰til y/o relevante para ustedes!\n",
        "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
        "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
        "  - **Recuerden adjuntar los documentos en su entrega**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D1tIRCi4oJJ"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzq2TjWCnu15"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "doc_paths = [] # rellenar con los path a sus documentos\n",
        "\n",
        "assert len(doc_paths) >= 2, \"Deben adjuntar un m칤nimo de 2 documentos\"\n",
        "\n",
        "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
        "assert total_paginas >= 50, f\"P치ginas insuficientes: {total_paginas}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r811-P71nizA"
      },
      "source": [
        "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
        "\n",
        "Vectorice los documentos y almacene sus representaciones de manera acorde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-yXAdCSn4JM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAUkP5zrnyBK"
      },
      "source": [
        "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
        "\n",
        "Habilite la soluci칩n RAG a trav칠s de una *chain* y gu치rdela en una variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPIySdDFn99l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycg5S5i_n-kL"
      },
      "source": [
        "#### **2.1.4 Verificaci칩n de respuestas (0.5 puntos)**\n",
        "\n",
        "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su soluci칩n para cada una. 쯉u soluci칩n RAG entrega las respuestas que esperaba?\n",
        "\n",
        "Ejemplo de tupla:\n",
        "- Pregunta: 쯈ui칠n es el presidente de Chile?\n",
        "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_UiEn1hoZYR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8d5zTMHoUgF"
      },
      "source": [
        "#### **2.1.5 Sensibilidad de Hiperpar치metros (0.5 puntos)**\n",
        "\n",
        "Extienda el an치lisis del punto 2.1.4 analizando c칩mo cambian las respuestas entregadas cambiando los siguientes hiperpar치metros:\n",
        "- `Tama침o del chunk`. (*쮺칩mo repercute que los chunks sean mas grandes o chicos?*)\n",
        "- `La cantidad de chunks recuperados`. (*쯈u칠 pasa si se devuelven muchos/pocos chunks?*)\n",
        "- `El tipo de b칰squeda`. (*쮺칩mo afecta el tipo de b칰squeda a las respuestas de mi RAG?*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDh_QgeXLGHc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENJiPPM0giX8"
      },
      "source": [
        "### **2.2 Agentes (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci칩n anterior, en esta secci칩n se busca habilitar **Agentes** para obtener informaci칩n a trav칠s de tools y as칤 responder la pregunta del usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V47l7Mjfrk0N"
      },
      "source": [
        "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas al motor de b칰squeda **Tavily**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6SLKwcWr0AG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SonB1A-9rtRq"
      },
      "source": [
        "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
        "\n",
        "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehJJpoqsr26-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvUIMdX6r0ne"
      },
      "source": [
        "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
        "\n",
        "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. Aseg칰rese que su agente responda en espa침ol. Por 칰ltimo, guarde el agente en una variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD1_n0wrsDI5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKV0JxK3r-XG"
      },
      "source": [
        "#### **2.2.4 Verificaci칩n de respuestas (0.3 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente y aseg칰rese que el agente est칠 ocupando correctamente las tools disponibles. 쮼n qu칠 casos el agente deber칤a ocupar la tool de Tavily? 쮼n qu칠 casos deber칤a ocupar la tool de Wikipedia?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqo2dsxvywW_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZbDTYiogquv"
      },
      "source": [
        "### **2.3 Multi Agente (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
        "\" width=\"450\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsecci칩n es encapsular las funcionalidades creadas en una soluci칩n multiagente con un **supervisor**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-iUfH0WvI6m"
      },
      "source": [
        "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
        "\n",
        "Transforme la soluci칩n RAG de la secci칩n 2.1 y el agente de la secci칩n 2.2 a *tools* (una tool por cada uno)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw1cfTtvv1AZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQYNjT_0vPCg"
      },
      "source": [
        "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
        "\n",
        "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv2ZY0BAv1RD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea3zWlvyvY7K"
      },
      "source": [
        "#### **2.3.3 Verificaci칩n de respuestas (0.25 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. 쮺칩mo var칤an las respuestas bajo este enfoque?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_1t0zkgv1qW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb8bdAmYvgwn"
      },
      "source": [
        "#### **2.3.4 An치lisis (0.25 puntos)**\n",
        "\n",
        "쯈u칠 diferencias tiene este enfoque con la soluci칩n *Router* vista en clases? Nombre al menos una ventaja y desventaja."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAUlJxqoLK5r"
      },
      "source": [
        "`escriba su respuesta ac치`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JWVSuWiZ8Mj"
      },
      "source": [
        "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
        "\n",
        "- Pregunta 1: \"Hola! mi nombre es Sebasti치n\"\n",
        "  - Respuesta esperada: \"Hola Sebasti치n! ...\"\n",
        "- Pregunta 2: \"Cual es mi nombre?\"\n",
        "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
        "  - **Respuesta esperada: \"Tu nombre es Sebasti치n\"**\n",
        "\n",
        "Para solucionar esto, se les solicita agregar un componente de **memoria** a la soluci칩n entregada en el punto 2.3.\n",
        "\n",
        "**Nota: El Bonus es v치lido <u>s칩lo para la secci칩n 2 de Large Language Models.</u>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6Y7tIPJLPfB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFc3jBT5g0kT"
      },
      "source": [
        "### **2.5 Despliegue (0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a trav칠s de `gradio`, una librer칤a especializada en el levantamiento r치pido de demos basadas en ML.\n",
        "\n",
        "Primero instalamos la librer칤a:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8TsvnCPbkIA"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJBztEUovKsF"
      },
      "source": [
        "Luego s칩lo deben ejecutar el siguiente c칩digo e interactuar con la interfaz a trav칠s del notebook o del link generado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3KedQSvg1-n"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "def agent_response(message, history):\n",
        "  '''\n",
        "  Funci칩n para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
        "  '''\n",
        "  # get chatbot response\n",
        "  response = ... # rellenar con la respuesta de su chat\n",
        "\n",
        "  # assert\n",
        "  assert type(response) == str, \"output de route_question debe ser string\"\n",
        "\n",
        "  # \"streaming\" response\n",
        "  for i in range(len(response)):\n",
        "    time.sleep(0.015)\n",
        "    yield response[: i+1]\n",
        "\n",
        "gr.ChatInterface(\n",
        "    agent_response,\n",
        "    type=\"messages\",\n",
        "    title=\"Chatbot MDS7202\", # Pueden cambiar esto si lo desean\n",
        "    description=\"Hola! Soy un chatbot muy 칰til :)\", # tambi칠n la descripci칩n\n",
        "    theme=\"soft\",\n",
        "    ).launch(\n",
        "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
        "        debug = False,\n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
